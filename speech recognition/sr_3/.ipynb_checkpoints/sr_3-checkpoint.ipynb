{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "virtual-shepherd",
   "metadata": {},
   "source": [
    "# Konuşma Tanıma III: Derin Öğrenme Tabanlı Konuşma Modeli İncelemesi\n",
    "<hr>\n",
    "\n",
    "### İçerik \n",
    "- Geçen dersler\n",
    "    - Ders 1 ve ders 2 özet\n",
    "    - Ders 2 ses smınıflandırma sonuçlarının tartışılması\n",
    "- Konuşma Tanımada bazı terimler\n",
    "- Ön bilgi: Sequence2sequence modeller\n",
    "- Hizalama Problemi: CTC Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-louisiana",
   "metadata": {},
   "source": [
    "# Ön Bilgi: Sequence2Sequence Modeller\n",
    "\n",
    "Basit anlamda bir sekanstan başka bir sekansı elde etmek için geliştirilen modellerdir. Sekans zamansal bilgiyi içeren bir veridir, örneğin cümleler (cümledeki bir kelime bir önceki kelimeye bağlıdır. Youtube'da video izlerken 'merhaba' sözcüğünden sonra 'arkadaşlar' kelimesini duymanız 'akşam' kelimesini duymanızdan daha olasıdır.) veya ses dosyaları (ses dosyaları sinyal olduğu için başlı başına bir zamansal veridir.)\n",
    "\n",
    "<img src=\"figures/seq2seq.png\">\n",
    "\n",
    "[image reference](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)\n",
    "\n",
    "\n",
    "### RNNs\n",
    "<img src=\"figures/rnn.png\">\n",
    "\n",
    "[image reference](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks)\n",
    "\n",
    "\n",
    "### Machine Translation\n",
    "<img src=\"figures/machine_trans.png\">\n",
    "\n",
    "[image reference](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "chemical-threshold",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_embedding(word):\n",
    "    return np.random.rand(1, 300).astype(np.float32)\n",
    "\n",
    "\n",
    "def get_word_list_english():\n",
    "    return [\"\", \"go\", \"came\", \"hello\", \"evening\", \"guys\"]\n",
    "\n",
    "\n",
    "words = [\"merhaba\", \"arkadaşlar\"]\n",
    "embeddings = [get_embedding(w) for w in words]\n",
    "embeddings = torch.tensor(embeddings)\n",
    "\n",
    "encoder = nn.RNN(input_size=300, hidden_size=512)\n",
    "decoder = nn.RNN(input_size=300, hidden_size=512)\n",
    "classifier = nn.Linear(512, len(get_word_list_english()))\n",
    "\n",
    "_, context = encoder(embeddings)\n",
    "\n",
    "predicted_word_list = []\n",
    "predicted_word = \"<start_token>\"\n",
    "hn = context\n",
    "\n",
    "for i in range(20):\n",
    "    decoder_input = torch.tensor(get_embedding(predicted_word)).unsqueeze(0)\n",
    "    outputs, hn = decoder(decoder_input, hn)\n",
    "\n",
    "    outputs = classifier(outputs)\n",
    "    probabilities = nn.Softmax(dim=2)(outputs)\n",
    " \n",
    "    predicted_word_index = torch.argmax(probabilities)\n",
    "    predicted_word = get_word_list_english()[predicted_word_index]\n",
    "    predicted_word_list.append(predicted_word)\n",
    "\n",
    "\n",
    "predicted_word_list = [\"hello\", \"guyz\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-engagement",
   "metadata": {},
   "source": [
    "Seste aslında bir sekans olduğu için işlenirken içindeki zamansal veriden yararlanılmalı ve bu veriye göre modeller tasarlanmalı/optimize edilmeli. \n",
    "\n",
    "<img src=\"figures/seq_signal_explain.png\">\n",
    "\n",
    "[image reference](https://distill.pub/2017/ctc/)\n",
    "\n",
    "### Hatırlatma\n",
    "Peki geçen hafta uyguladığımız ses sınıflandırma modelinde bu zamansal veriyi kullanıyor muyduk?\n",
    "<img src=\"../sr_2/figures/model.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-programming",
   "metadata": {},
   "source": [
    "### Konuşma Tanıma\n",
    "##### Mimari \n",
    "\n",
    "<img src=\"figures/deepspeech_model.png\">\n",
    "\n",
    "[image reference](https://arxiv.org/abs/1412.5567)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "divided-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import librosa\n",
    "signal, sampling_rate = librosa.load(\"../sr_1/example_sound.wav\", sr=None)\n",
    "mel_spectrogram = librosa.feature.melspectrogram(signal, sampling_rate)\n",
    "\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(librosa.power_to_db(mel_spectrogram, ref=np.max), y_axis='mel', x_axis='time');\n",
    "plt.colorbar(format='%+2.0f dB');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "persistent-question",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 211, 40])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_phoneme_list():\n",
    "    # http://www.speech.cs.cmu.edu/cgi-bin/cmudict\n",
    "    return [\" \",\"AA\",\"AE\",\"AH\",\"AO\",\"AW\",\"AY\",\"B\",\"CH\",\"D\",\"DH\",\"EH\",\"ER\",\"EY\",\"F\",\"G\",\"HH\",\"IH\",\"IY\",\"JH\",\"K\",\"L\",\"M\",\"N\",\"NG\",\"OW\",\"OY\",\"P\",\"R\",\"S\",\"SH\",\"T\",\"TH\",\"UH\",\"UW\",\"V\",\"W\",\"Y\",\"Z\",\"ZH\"]\n",
    "\n",
    "\n",
    "embeddings = torch.from_numpy(mel_spectrogram).T.unsqueeze(0)\n",
    "\n",
    "acustic_model = nn.RNN(input_size=128, hidden_size=512)\n",
    "classifier = nn.Linear(512, len(get_phoneme_list()))\n",
    "\n",
    "outputs, context = acustic_model(embeddings)\n",
    "outputs = classifier(outputs)\n",
    "probabilities = nn.Softmax(dim=2)(outputs)\n",
    "print(probabilities.shape)\n",
    "\n",
    "# loss ???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-resident",
   "metadata": {},
   "source": [
    "### Olası çıktılar\n",
    "\n",
    "<img src=\"figures/hello.png\">\n",
    "<img src=\"figures/possible_out.png\">\n",
    "\n",
    "[image references](https://distill.pub/2017/ctc/)\n",
    "\n",
    "<br>\n",
    "\n",
    "### Örnek Hizalama (Alignment)\n",
    "\n",
    "<img src=\"figures/ctc_paper_fig.png\">\n",
    "\n",
    "[image reference](http://www.cs.toronto.edu/~graves/icml_2006.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-metabolism",
   "metadata": {},
   "source": [
    "### CTC Loss\n",
    "\n",
    "Hizalama yapılırken çıkarılan harflerin direk birleştirilememesindeki en büyük problem ardarda tekrar eden harflerdir. Mesela \"Hello\" kelimesinde iki tane 'l' harfi ardarda iki kere yazılmıştır. Tanıma sonucu olarak alınan 'hhhheeeelllllllllllllloooo' çıktısı direk birleştirilirse 'helo' olarak çıktı alınır ki bu yanlıştır. Bu sorunu çözmek için CTC Loss bir tane boşluk karakteri ϵ tanımlar. Bu karakterin herbir karakteri ayırması beklenir. \n",
    "\n",
    "<img src=\"figures/alignment_ex.png\">\n",
    "\n",
    "[image reference](https://distill.pub/2017/ctc)\n",
    "\n",
    "\n",
    "### ε (Epsilon) nasıl öğreniliyor?\n",
    "\n",
    "<img src=\"figures/ep_learning.png\">\n",
    "\n",
    "[image reference](https://distill.pub/2017/ctc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-bulletin",
   "metadata": {},
   "source": [
    "### CTC İçerisinde Neler Oluyor?\n",
    "\n",
    "<img src=\"figures/alignment_cat.png\">\n",
    "\n",
    "[image reference](https://towardsdatascience.com/better-faster-speech-recognition-with-wav2letters-auto-segmentation-criterion-765efd55449)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "numerical-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([211, 1, 40])\n",
      "torch.Size([1])\n",
      "tensor(-3.6404, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# loss = nn.CTCLoss()(probabilities, target, input_lengths, target_lengths)\n",
    "\n",
    "def get_vocab():\n",
    "    return {\"a\": 0, \"b\": 1, \"c\": 2, \"ç\": 3, \"d\": 4, \"e\": 5, \"f\": 6, \"g\": 7, \"ğ\": 8, \"h\": 9, \"ı\": 10, \"i\": 11,\n",
    "            \"j\": 12, \"k\": 13, \"l\": 14, \"m\":15, \"n\": 16, \"o\": 17, \"ö\": 18, \"p\": 19, \"r\":20, \"s\": 21, \"ş\": 22,\n",
    "            \"t\": 23 ,\"u\": 24, \"ü\": 25, \"v\": 26, \"y\": 27, \"z\":28, ' ': 29, \"1\": 30}\n",
    "\n",
    "\n",
    "def char_to_num(sentence):\n",
    "    return torch.tensor([get_vocab()[i] for i in sentence]).unsqueeze(0)\n",
    "\n",
    "\n",
    "target_sentence = \"inşaat için 1 milyar dolarlık yatırım gerekiyor\"\n",
    "target = char_to_num(target_sentence)\n",
    "\n",
    "T = 211                   # Input sequence length\n",
    "C = 40                    # Number of classes\n",
    "N = 1                     # Batch size\n",
    "S = len(target_sentence)  # Target sequence length \n",
    "\n",
    "probabilities = probabilities.requires_grad_().transpose(0,1)\n",
    "\n",
    "\n",
    "input_lengths = torch.tensor([T], dtype=torch.int)\n",
    "target_lengths = torch.tensor([S], dtype=torch.int)\n",
    "probabilities = probabilities\n",
    "\n",
    "ctc_loss = nn.CTCLoss()\n",
    "loss = ctc_loss(probabilities, target, input_lengths, target_lengths)\n",
    "loss.backward()\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-harris",
   "metadata": {},
   "source": [
    "#### Önemli Noktalar\n",
    "- Fonem listemizdeki boşluk fonemi\n",
    "- Mel-spectrogram tensor transpoze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-adapter",
   "metadata": {},
   "source": [
    "# Referanslar\n",
    "- https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "- https://towardsdatascience.com/automatic-speech-recognition-breaking-down-components-of-speech-85d065061517\n",
    "- https://www.dyslexia-reading-well.com/44-phonemes-in-english.html\n",
    "\n",
    "\n",
    "\n",
    "- https://pytorch.org/docs/stable/generated/torch.nn.RNN.html?highlight=rnn#torch.nn.RNN\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
