{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "complimentary-order",
   "metadata": {},
   "source": [
    "# Konuşma Tanıma IV: Derin Öğrenme Tabanlı Konuşma Tanıma Mozilla Deepspeech\n",
    "<hr>\n",
    "\n",
    "### İçerik \n",
    "- Geçen dersin özeti\n",
    "- Deepspeech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-collective",
   "metadata": {},
   "source": [
    "## Deepspeech Mimarisi\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "<img src=\"figures/deepspeech_paper.png\">\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "### Özellikleri\n",
    "- End-to-end bir mimariye sahip\n",
    "- Geleneksel SR çözümleri (HMM) gibi karışık bir mimariye sahip değil\n",
    "- Geleneksel SR çözümleri gibi bir fonem setine ihtiyaç duymuyor\n",
    "- RNN tabanlı bir mimariye sahip\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "### Model Kurulumu ve Formülasyon\n",
    "> Let a single utterance x and label y be sampled from a training set X = {(x(1), y(1)), (x(2), y(2)), . . .}. Each utterance, x(i), is a time-series of length T(i) where <b>every time-slice is a vector of audio features</b>, x(i)\n",
    "t , t = 1, . . . , T(i). We use spectrograms as\n",
    "our features, so x(i)\n",
    "t,p denotes the power of the p’th frequency bin in the audio frame at time t. The\n",
    "<b>goal of our RNN is to convert an input sequence x into a sequence of character probabilities for the transcription y</b>, with ˆyt = P(ct|x), where ct ∈ {a,b,c, . . . , z, space, apostrophe, blank}.\n",
    "\n",
    "<br/>\n",
    "\n",
    "Elimizdeki veri kümesinde bulunan ses dosyalarımızın özniteliklerine x, yazılarına y diyoruz, X = {(x(1), y(1)), (x(2), y(2)), . . .}. Herbir örnek x(i) aslında bir spectrogramı ifade ediyor. Geçen derslerde de öğrendiğimiz gibi ses dosyalarının uzunlukları farklı olduğu için herbir spectrogram uzunluklarımızda farklı oluyor. Herbir uzunluğu T(i) olarak ifade ediyoruz. Yine geçen derslerde öğrendiğimiz gibi RNN yapısını içeren bir akustik model spectrogramları parça parça alıyor ve bu parçalara karşılık gelen harfi bulmaya çalışıyor. Bu spectrogram parçaları x(i)(t) olarak ifade edilir. \n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "<img src=\"../sr_3/figures/deepspeech_model.png\">\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "ilk 3 katmanda aynı işlem uygulanır, 3 farklı lineer sınıflandırıcı üstüste konumlandırılır ve girdi olarak alınınan spectrogram parçasından yine bir öznitelik elde edilir.\n",
    "\n",
    "<img src=\"figures/formula1.png\">\n",
    "\n",
    "<br/>\n",
    "\n",
    "4. katmanda çift yönlü RNN yapısı bulunmaktadır. RNN çift yönlü olduğu için her iki yönde gizli katmanlar bulunmakta. Burada zamansal bilgiden faydalanılmaktadır.\n",
    "\n",
    "<img src=\"figures/f2.png\">\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"figures/f3_0.png\" width=800 hegiht=200>\n",
    "<img src=\"figures/f3.png\">\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "Son katmandan elde edilen çıktılar aslında karakterlerimize ait olasılık dağılımımız olmaktadır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-stationery",
   "metadata": {},
   "source": [
    "## Ön Eğitimli Model Denemesi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-insulation",
   "metadata": {},
   "source": [
    "## Ön eğitimli modelleri indir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "according-medium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-28 12:47:20--  https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.pbmm\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github-releases.githubusercontent.com/60273704/8b25f180-3b0f-11eb-8fc1-de4f4ec3b5a3?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210328%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210328T094728Z&X-Amz-Expires=300&X-Amz-Signature=64fd55c8b7a03ab9750c31e391e469e8dac75e329d9231a0ef4ac94bea0143b3&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=60273704&response-content-disposition=attachment%3B%20filename%3Ddeepspeech-0.9.3-models.pbmm&response-content-type=application%2Foctet-stream [following]\n",
      "--2021-03-28 12:47:28--  https://github-releases.githubusercontent.com/60273704/8b25f180-3b0f-11eb-8fc1-de4f4ec3b5a3?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210328%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210328T094728Z&X-Amz-Expires=300&X-Amz-Signature=64fd55c8b7a03ab9750c31e391e469e8dac75e329d9231a0ef4ac94bea0143b3&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=60273704&response-content-disposition=attachment%3B%20filename%3Ddeepspeech-0.9.3-models.pbmm&response-content-type=application%2Foctet-stream\n",
      "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.109.154, 185.199.111.154, 185.199.110.154, ...\n",
      "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.109.154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 188915987 (180M) [application/octet-stream]\n",
      "Saving to: ‘deepspeech-0.9.3-models.pbmm’\n",
      "\n",
      "deepspeech-0.9.3-mo 100%[===================>] 180,16M  1,43MB/s    in 49s     \n",
      "\n",
      "2021-03-28 12:48:26 (3,64 MB/s) - ‘deepspeech-0.9.3-models.pbmm’ saved [188915987/188915987]\n",
      "\n",
      "--2021-03-28 12:48:26--  https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.scorer\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github-releases.githubusercontent.com/60273704/924cff80-3b0f-11eb-878c-cacaa2a0d946?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210328%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210328T094705Z&X-Amz-Expires=300&X-Amz-Signature=8fd0a5fa962e1cec7241421749f4e46368ac0606439c8ab6c3cdc8927686bfcd&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=60273704&response-content-disposition=attachment%3B%20filename%3Ddeepspeech-0.9.3-models.scorer&response-content-type=application%2Foctet-stream [following]\n",
      "--2021-03-28 12:48:35--  https://github-releases.githubusercontent.com/60273704/924cff80-3b0f-11eb-878c-cacaa2a0d946?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210328%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210328T094705Z&X-Amz-Expires=300&X-Amz-Signature=8fd0a5fa962e1cec7241421749f4e46368ac0606439c8ab6c3cdc8927686bfcd&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=60273704&response-content-disposition=attachment%3B%20filename%3Ddeepspeech-0.9.3-models.scorer&response-content-type=application%2Foctet-stream\n",
      "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.109.154, 185.199.111.154, 185.199.110.154, ...\n",
      "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.109.154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 953363776 (909M) [application/octet-stream]\n",
      "Saving to: ‘deepspeech-0.9.3-models.scorer’\n",
      "\n",
      "deepspeech-0.9.3-mo 100%[===================>] 909,20M  3,94MB/s    in 6m 22s  \n",
      "\n",
      "2021-03-28 12:55:05 (2,38 MB/s) - ‘deepspeech-0.9.3-models.scorer’ saved [953363776/953363776]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.pbmm -O deepspeech-0.9.3-models.pbmm\n",
    "!wget https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.scorer -O deepspeech-0.9.3-models.scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "single-murder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepspeech\n",
    "model_file_path = \"deepspeech-0.9.3-models.pbmm\"\n",
    "model = deepspeech.Model(model_file_path)\n",
    "\n",
    "# Modelin incelenmesi\n",
    "# https://github.com/mozilla/DeepSpeech/blob/master/training/deepspeech_training/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-socket",
   "metadata": {},
   "source": [
    "## Örnek Sesi Yazıya çevir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "therapeutic-russia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-28 13:04:01.536853: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
      "2021-03-28 13:04:01.536880: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Loading model from file deepspeech-0.9.3-models.pbmm\n",
      "TensorFlow: v2.3.0-6-g23ad988\n",
      "DeepSpeech: v0.9.3-0-gf2e9c85\n",
      "2021-03-28 13:04:01.623134: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-28 13:04:01.623853: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2021-03-28 13:04:01.644061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-03-28 13:04:01.644406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:09:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5\n",
      "coreClock: 1.665GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2021-03-28 13:04:01.644441: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
      "2021-03-28 13:04:01.645336: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2021-03-28 13:04:01.646399: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2021-03-28 13:04:01.646525: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2021-03-28 13:04:01.647542: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-03-28 13:04:01.648063: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-03-28 13:04:01.648098: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\n",
      "2021-03-28 13:04:01.648104: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-03-28 13:04:01.710009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-03-28 13:04:01.710031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2021-03-28 13:04:01.710034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "Loaded model in 0.0967s.\n",
      "Loading scorer from files deepspeech-0.9.3-models.scorer\n",
      "Loaded scorer in 0.000147s.\n",
      "Running inference.\n",
      "taking advantage of this the squires you men redoubled their efforts and encouraged by robins and the little strollers cries father weight to him\n",
      "Inference took 2.360s for 7.950s audio file.\n"
     ]
    }
   ],
   "source": [
    "!deepspeech --model deepspeech-0.9.3-models.pbmm --scorer deepspeech-0.9.3-models.scorer --audio 61-70968-0035.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-agreement",
   "metadata": {},
   "source": [
    "# Sıfırdan Model Eğitimi\n",
    "\n",
    "Common Voice Türkçe veri kümesi üzerinde sıfırdan eğitim yapacağız. Eğitimi yaparken [Deepspeech.v.0.9.3 dokümanı](https://deepspeech.readthedocs.io/en/v0.9.3/TRAINING.html)ndaki adımları izleyeceğiz. Veri kümemizi kütüphanenin okuması için uygun hale getirmemiz lazım. Bunun için import_cv2 script'i yardımıyla veri kümemizi uygun formata dönüştürüyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "overhead-karaoke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'DeepSpeech'...\n",
      "remote: Enumerating objects: 173, done.\u001b[K\n",
      "remote: Counting objects: 100% (173/173), done.\u001b[K\n",
      "remote: Compressing objects: 100% (102/102), done.\u001b[K\n",
      "remote: Total 23386 (delta 57), reused 135 (delta 47), pack-reused 23213\u001b[K\n",
      "Receiving objects: 100% (23386/23386), 49.23 MiB | 4.01 MiB/s, done.\n",
      "Resolving deltas: 100% (16055/16055), done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "!git clone https://github.com/mozilla/DeepSpeech.git\n",
    "os.chdir(\"DeepSpeech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cheap-drain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TSV file:  /home/emre/Datasets/speech/Common Voice/tr/cv-corpus-5-2020-06-22/tr/test.tsv\n",
      "Importing mp3 files...\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "Progress |#################################################### |  98% completedImported 20 samples.\n",
      "Skipped 1618 samples that failed on transcript validation.\n",
      "Final amount of imported audio: 0:00:52 from 2:02:02.\n",
      "Saving new DeepSpeech-formatted CSV file to:  /home/emre/Datasets/speech/Common Voice/tr/cv-corpus-5-2020-06-22/tr/clips/test.csv\n",
      "Writing CSV file for DeepSpeech.py as:  /home/emre/Datasets/speech/Common Voice/tr/cv-corpus-5-2020-06-22/tr/clips/test.csv\n",
      "Progress |#####################################################| 100% completed\n",
      "Loading TSV file:  /home/emre/Datasets/speech/Common Voice/tr/cv-corpus-5-2020-06-22/tr/dev.tsv\n",
      "Importing mp3 files...\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "Progress |#################################################### |  98% completedImported 3 samples.\n",
      "Skipped 1635 samples that failed on transcript validation.\n",
      "Final amount of imported audio: 0:00:05 from 1:51:48.\n",
      "Saving new DeepSpeech-formatted CSV file to:  /home/emre/Datasets/speech/Common Voice/tr/cv-corpus-5-2020-06-22/tr/clips/dev.csv\n",
      "Writing CSV file for DeepSpeech.py as:  /home/emre/Datasets/speech/Common Voice/tr/cv-corpus-5-2020-06-22/tr/clips/dev.csv\n",
      "Progress |#####################################################| 100% completed\n",
      "Loading TSV file:  /home/emre/Datasets/speech/Common Voice/tr/cv-corpus-5-2020-06-22/tr/train.tsv\n",
      "Importing mp3 files...\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "Progress |###################################################  |  97% completedImported 4 samples.\n",
      "Skipped 1817 samples that failed on transcript validation.\n",
      "Final amount of imported audio: 0:00:09 from 1:57:46.\n",
      "Saving new DeepSpeech-formatted CSV file to:  /home/emre/Datasets/speech/Common Voice/tr/cv-corpus-5-2020-06-22/tr/clips/train.csv\n",
      "Writing CSV file for DeepSpeech.py as:  /home/emre/Datasets/speech/Common Voice/tr/cv-corpus-5-2020-06-22/tr/clips/train.csv\n",
      "Progress |#####################################################| 100% completed\n",
      "Loading TSV file:  /home/emre/Datasets/speech/Common Voice/tr/cv-corpus-5-2020-06-22/tr/validated.tsv\n",
      "Importing mp3 files...\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "Progress |#################################################### |  98% completedImported 368 samples.\n",
      "Skipped 18167 samples that failed on transcript validation.\n",
      "Final amount of imported audio: 0:13:57 from 19:48:57.\n",
      "Saving new DeepSpeech-formatted CSV file to:  /home/emre/Datasets/speech/Common Voice/tr/cv-corpus-5-2020-06-22/tr/clips/validated.csv\n",
      "Writing CSV file for DeepSpeech.py as:  /home/emre/Datasets/speech/Common Voice/tr/cv-corpus-5-2020-06-22/tr/clips/validated.csv\n",
      "Progress |#####################################################| 100% completed\n",
      "Saving new DeepSpeech-formatted CSV file to:  /home/emre/Datasets/speech/Common Voice/tr/cv-corpus-5-2020-06-22/tr/clips/train-all.csv\n",
      "Writing CSV file for DeepSpeech.py as:  /home/emre/Datasets/speech/Common Voice/tr/cv-corpus-5-2020-06-22/tr/clips/train-all.csv\n",
      "Progress |#####################################################| 100% completed\n",
      "Loading TSV file:  /home/emre/Datasets/speech/Common Voice/tr/cv-corpus-5-2020-06-22/tr/other.tsv\n",
      "Importing mp3 files...\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
      "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress |###################################################  |  97% completedImported 29 samples.\n",
      "Skipped 255 samples that failed on transcript validation.\n",
      "Final amount of imported audio: 0:01:08 from 0:19:00.\n",
      "Saving new DeepSpeech-formatted CSV file to:  /home/emre/Datasets/speech/Common Voice/tr/cv-corpus-5-2020-06-22/tr/clips/other.csv\n",
      "Writing CSV file for DeepSpeech.py as:  /home/emre/Datasets/speech/Common Voice/tr/cv-corpus-5-2020-06-22/tr/clips/other.csv\n",
      "Progress |#####################################################| 100% completed\n",
      "Progress |#####################################################| 100% completed\n",
      "Progress |#####################################################| 100% completed\n",
      "Progress |#####################################################| 100% completed\n",
      "Progress |#####################################################| 100% completed\n",
      "Progress |#####################################################| 100% completed\n"
     ]
    }
   ],
   "source": [
    "# ! Hangi dilde eğitim yapıyorsak alfabe oluşturulması gerekiyor.\n",
    "alphabet = \"\"\"a\n",
    "b\n",
    "c\n",
    "ç\n",
    "d\n",
    "e\n",
    "f\n",
    "g\n",
    "ğ\n",
    "h\n",
    "i\n",
    "ı\n",
    "j\n",
    "k\n",
    "l\n",
    "m\n",
    "n\n",
    "o\n",
    "ö\n",
    "p\n",
    "r\n",
    "s\n",
    "ş\n",
    "t\n",
    "u\n",
    "ü\n",
    "v\n",
    "y\n",
    "z\n",
    "\"\"\"\n",
    "open(\"alphabet.txt\", \"w\").write(alphabet)\n",
    "\n",
    "!python bin/import_cv2.py --filter_alphabet \"alphabet.txt\" \"/home/emre/Datasets/speech/Common Voice/tr/cv-corpus-5-2020-06-22/tr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "funky-gambling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I Loading best validating checkpoint from /home/emre/.local/share/deepspeech/checkpoints/best_dev-8\n",
      "I Loading variable from checkpoint: beta1_power\n",
      "I Loading variable from checkpoint: beta2_power\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam_1\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam_1\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/bias/Adam\n",
      "I Loading variable from checkpoint: layer_1/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_1/weights/Adam\n",
      "I Loading variable from checkpoint: layer_1/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/bias/Adam\n",
      "I Loading variable from checkpoint: layer_2/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_2/weights/Adam\n",
      "I Loading variable from checkpoint: layer_2/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/bias/Adam\n",
      "I Loading variable from checkpoint: layer_3/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_3/weights/Adam\n",
      "I Loading variable from checkpoint: layer_3/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/bias/Adam\n",
      "I Loading variable from checkpoint: layer_5/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_5/weights/Adam\n",
      "I Loading variable from checkpoint: layer_5/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/bias/Adam\n",
      "I Loading variable from checkpoint: layer_6/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "I Loading variable from checkpoint: layer_6/weights/Adam\n",
      "I Loading variable from checkpoint: layer_6/weights/Adam_1\n",
      "I Loading variable from checkpoint: learning_rate\n",
      "I STARTING Optimization\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:47 | Steps: 4 | Loss: 29.701189      \n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:01 | Steps: 3 | Loss: 28.810555 | Dataset: /home/emre/Datasets/speech/Common Voice/tr/cv-corpus-5-2020-06-22/tr/clips/dev.csv\n",
      "I Saved new best validating model with loss 28.810555 to: /home/emre/.local/share/deepspeech/checkpoints/best_dev-12\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:46 | Steps: 4 | Loss: 29.071598      \n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:01 | Steps: 3 | Loss: 28.101000 | Dataset: /home/emre/Datasets/speech/Common Voice/tr/cv-corpus-5-2020-06-22/tr/clips/dev.csv\n",
      "I Saved new best validating model with loss 28.101000 to: /home/emre/.local/share/deepspeech/checkpoints/best_dev-16\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 |   Training | Elapsed Time: 0:01:47 | Steps: 4 | Loss: 27.188189      \n",
      "Epoch 2 | Validation | Elapsed Time: 0:00:01 | Steps: 3 | Loss: 25.531780 | Dataset: /home/emre/Datasets/speech/Common Voice/tr/cv-corpus-5-2020-06-22/tr/clips/dev.csv\n",
      "I Saved new best validating model with loss 25.531780 to: /home/emre/.local/share/deepspeech/checkpoints/best_dev-20\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 |   Training | Elapsed Time: 0:00:50 | Steps: 2 | Loss: 21.379120      ^C\n"
     ]
    }
   ],
   "source": [
    "!python3 DeepSpeech.py --train_files \"/home/emre/Datasets/speech/Common Voice/tr/cv-corpus-5-2020-06-22/tr/clips/train.csv\" --dev_files \"/home/emre/Datasets/speech/Common Voice/tr/cv-corpus-5-2020-06-22/tr/clips/dev.csv\" --test_files \"/home/emre/Datasets/speech/Common Voice/tr/cv-corpus-5-2020-06-22/tr/clips/test.csv\" --export_dir ~/deepspeech_checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-nudist",
   "metadata": {},
   "source": [
    "# Referanslar\n",
    "- https://deepspeech.readthedocs.io/en/v0.9.3/TRAINING.html\n",
    "- https://deepspeech.readthedocs.io/en/v0.9.3/USING.html\n",
    "- https://arxiv.org/abs/1412.5567\n",
    "- https://github.com/mozilla/DeepSpeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-powder",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
